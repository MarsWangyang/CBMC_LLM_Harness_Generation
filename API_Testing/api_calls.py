import os
from typing import Optional, Dict, Any, List
from dotenv import load_dotenv
import anthropic
from openai import OpenAI
import google.generativeai as genai
from datetime import datetime

load_dotenv()

class LLMClient:
    def __init__(self):
        self.anthropic_client = anthropic.Client(api_key=os.getenv("ANTHROPIC_API_KEY"))
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
        self.gemini_model = genai.GenerativeModel('gemini-pro')
        
        # Directory structure
        self.responses_dir = "responses"
        self.code_dir = "code"
        self.harness_dir = "harnesses"
        
        # Create necessary directories
        for directory in [self.responses_dir, self.code_dir, self.harness_dir]:
            os.makedirs(directory, exist_ok=True)
            
        # Track generated harnesses
        self.harness_files = {}

        # Detailed prompt template with examples for CBMC harness generation
        self.default_prompt_template = """
        You are a verification engineer specializing in CBMC model checking. Generate a CBMC harness function for the given C code.

        Here's an example of a good CBMC harness structure:
        ```c
        int main() {{
            // Declare non-deterministic inputs
            int input = __CPROVER_nondet_int();
            
            // Add assumptions to constrain inputs
            __CPROVER_assume(input >= MIN_VALUE && input <= MAX_VALUE);
            
            // Allocate and initialize data structures if needed
            struct data *ptr = malloc(sizeof(struct data));
            __CPROVER_assume(ptr != NULL);
            
            // Call the function under test
            result = tested_function(input, ptr);
            
            // Add assertions to verify properties
            assert(result >= 0);
            
            // Free allocated memory
            free(ptr);
        }}
        ```

        For the following C code, create a harness that:
        1. Creates a complete main() function for CBMC verification
        2. Uses __CPROVER_nondet_* functions for all inputs:
           - __CPROVER_nondet_int() for integers
           - __CPROVER_nondet_char() for characters
           - __CPROVER_nondet_float() for floats
           - __CPROVER_nondet_bool() for booleans
           - __CPROVER_nondet_pointer() for pointers
        3. Adds __CPROVER_assume() statements to:
           - Set valid ranges for all inputs
           - Ensure pointers are valid when needed
           - Prevent undefined behavior
        4. Includes assert() statements to verify:
           - Function return values
           - Output parameters
           - System state after function calls
           - Memory safety properties
        5. Properly handles memory:
           - Allocates required structures
           - Initializes memory properly
           - Frees all allocated memory
        6. Includes detailed comments explaining:
           - Each assumption's purpose
           - Properties being verified
           - Expected behavior
           - Edge cases considered

        Original C Code:
        {}

        Provide the complete harness implementation with thorough verification coverage."""

    def read_c_file(self, filepath: str) -> str:
        with open(filepath, 'r') as f:
            return f.read()

    def save_c_file(self, content: str, filename: str, file_type: str = "code") -> str:
        """
        Save C file content to appropriate directory based on file type
        
        Args:
            content: The C code content to save
            filename: Name of the file
            file_type: Type of file ("code", "harness")
            
        Returns:
            str: Path to the saved file
        """
        if file_type == "harness":
            directory = self.harness_dir
        else:
            directory = self.code_dir
            
        filepath = os.path.join(directory, filename)
        with open(filepath, 'w') as f:
            f.write(content)
        return filepath

    def save_harness(self, harness_code: str, original_file: str, model: str) -> str:
        """
        Save a generated harness to a dedicated file
        
        Args:
            harness_code: The generated harness code
            original_file: Name of the original C file
            model: Name of the LLM that generated the harness
            
        Returns:
            str: Path to the saved harness file
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = os.path.splitext(os.path.basename(original_file))[0]
        harness_filename = f"{base_name}_harness_{model}_{timestamp}.c"
        
        # Add header comment
        header = f"""/*
 * CBMC Harness generated for {original_file}
 * Generated by: {model}
 * Generated at: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
 */

"""
        full_harness = header + harness_code
        
        # Save the harness
        harness_path = self.save_c_file(full_harness, harness_filename, "harness")
        
        # Track the harness file
        if original_file not in self.harness_files:
            self.harness_files[original_file] = {}
        self.harness_files[original_file][model] = harness_path
        
        return harness_path

    def process_c_code(self, file_path: str, prompt_template: str = None, model: str = "claude") -> Dict[str, str]:
        """
        Process C code and generate harness using specified LLM
        
        Returns:
            Dict containing 'response', 'harness_code', and 'harness_path'
        """
        code_content = self.read_c_file(file_path)
        result = {
            'response': None,
            'harness_code': None,
            'harness_path': None
        }
        
        if prompt_template is None:
            prompt_template = self.default_prompt_template
            
        # Use safer string formatting
        prompt = prompt_template.format(code_content)
        
        # Model-specific prompting adjustments
        if model == "claude":
            prompt = self._adjust_claude_prompt(prompt)
            response = self.call_claude(prompt)
        elif model == "gpt":
            prompt = self._adjust_gpt_prompt(prompt)
            response = self.call_gpt(prompt)
        elif model == "gemini":
            prompt = self._adjust_gemini_prompt(prompt)
            response = self.call_gemini(prompt)
        
        result['response'] = response
            
        if response:
            try:
                harness_code = self._extract_c_code(response)
                if harness_code:
                    # Validate harness code
                    self._validate_harness(harness_code)
                    
                    # Save harness to dedicated file
                    harness_path = self.save_harness(harness_code, file_path, model)
                    print(f"Saved {model}'s harness to: {harness_path}")
                    
                    result['harness_code'] = harness_code
                    result['harness_path'] = harness_path
                    
            except Exception as e:
                print(f"Error processing harness from {model}: {str(e)}")
                
        return result

    def _adjust_claude_prompt(self, prompt: str) -> str:
        """Add Claude-specific instructions for better harness generation"""
        return prompt + """
        Create a CBMC harness that verifies the FreeRTOS code. Focus specifically on:

        1. Non-deterministic inputs:
        ```c
        // Example of proper input declaration
        int nondet_priority = __CPROVER_nondet_int();
        __CPROVER_assume(nondet_priority >= 0 && nondet_priority <= configMAX_PRIORITIES);
        ```

        2. Task and Queue verification:
        ```c
        // Example of task/queue verification
        void *queue_handle = xQueueCreate(length, item_size);
        __CPROVER_assume(queue_handle != NULL);
        ```

        3. Memory safety checks:
        ```c
        // Example of memory safety verification
        void *buffer = malloc(size);
        __CPROVER_assume(buffer != NULL);
        // ... use buffer ...
        free(buffer);
        ```

        Provide ONLY the complete harness code without any explanations. The code should:
        - Be wrapped in ```c code blocks
        - Be complete and compilable
        - Include all necessary headers
        - Have proper error handling
        - Verify key FreeRTOS properties"""

    def _adjust_gpt_prompt(self, prompt: str) -> str:
        """Add GPT-specific instructions for better harness generation"""
        return prompt + """
        Format your response as follows:
        1. Start with the complete harness code in a ```c code block
        2. Follow with explanations of:
           - Assumptions made
           - Properties being verified
           - Potential edge cases considered
        """

    def _adjust_gemini_prompt(self, prompt: str) -> str:
        """Add Gemini-specific instructions for better harness generation"""
        return prompt + """
        Analyze the code and create a CBMC harness following these exact steps:

        1. First identify the key functions that need verification:
           - Main application entry points
           - Task creation functions
           - Critical data handling functions
           - Resource management functions

        2. For each function, determine:
           - Input parameters that need nondet values
           - Valid ranges for each input
           - Required assumptions for proper execution
           - Properties that should be verified

        3. Create the harness using this structure:
        ```c
        int main() {
            // 1. Declare all nondet inputs
            type1 input1 = __CPROVER_nondet_type();
            type2 input2 = __CPROVER_nondet_type();

            // 2. Add assumptions for valid ranges
            __CPROVER_assume(input1 >= MIN && input1 <= MAX);
            __CPROVER_assume(input2 != NULL);

            // 3. Initialize required structures
            // 4. Call functions under test
            // 5. Add assertions
            // 6. Cleanup resources
        }
        ```

        Provide only the complete, correct CBMC harness code without any additional explanation.
        """

    def _validate_harness(self, harness_code: str):
        """Basic validation of harness code"""
        required_elements = [
            ("main function", "int main("),
            ("CPROVER assume", "__CPROVER_assume"),
            ("nondet inputs", "__CPROVER_nondet_"),
        ]
        
        for element, pattern in required_elements:
            if pattern not in harness_code:
                print(f"Warning: Harness might be missing {element}")

    def _extract_c_code(self, response: str) -> Optional[str]:
        """Extract C code from response text with improved handling"""
        # Try different code block markers
        markers = [("```c", "```"), ("```C", "```"), ("```cpp", "```"), ("```", "```")]
        
        for start_marker, end_marker in markers:
            if start_marker in response:
                start = response.find(start_marker) + len(start_marker)
                end = response.find(end_marker, start)
                if end != -1:
                    code = response[start:end].strip()
                    # Basic validation of extracted code
                    if "int main" in code and "__CPROVER" in code:
                        return code
        
        print("Warning: Could not extract valid harness code from response")
        return None

    def save_analysis_report(self, original_code: str, model_responses: Dict[str, str], file_path: str):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"{self.responses_dir}/harness_analysis_{timestamp}.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("CBMC HARNESS GENERATION REPORT\n")
            f.write("=" * 50 + "\n\n")
            
            f.write("Original C Code:\n")
            f.write("-" * 20 + "\n")
            f.write(original_code + "\n\n")
            
            for model, response in model_responses.items():
                f.write(f"{model.upper()} GENERATED HARNESS:\n")
                f.write("-" * 20 + "\n")
                
                harness_code = self._extract_c_code(response)
                if harness_code:
                    f.write("Harness Code:\n")
                    f.write(harness_code + "\n\n")
                    
                    f.write("Full Response:\n")
                    f.write(response + "\n\n")
                else:
                    f.write("No valid harness code found in response.\n\n")
                    
            f.write("=" * 50 + "\n")
        return report_file

    def call_claude(self, prompt: str, model: str = "claude-3-opus-20240229",
                   max_tokens: int = 1000, temperature: float = 0.7) -> str:
        """Call the Claude API with the given prompt"""
        try:
            response = self.anthropic_client.messages.create(
                model=model,
                max_tokens=max_tokens,
                temperature=temperature,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                system="You are a verification expert who specializes in creating CBMC harness functions. Always respond with compilable C code."
            )
            
            # Debug logging
            print(f"Claude response type: {type(response)}")
            print(f"Claude response content: {response.content}")
            
            # Extract the text from the response
            if hasattr(response, 'content') and isinstance(response.content, list):
                content = response.content[0].text if response.content else None
            else:
                content = str(response.content) if response.content else None
            
            return content
            
        except Exception as e:
            print(f"Detailed error calling Claude API: {str(e)}")
            return None

    def call_gpt(self, prompt: str, model: str = "gpt-4-turbo-preview",
                 max_tokens: int = 1000, temperature: float = 0.7) -> str:
        """Call the GPT API with the given prompt"""
        try:
            response = self.openai_client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=max_tokens,
                temperature=temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error calling GPT API: {str(e)}")
            return None

    def call_gemini(self, prompt: str, 
                    max_tokens: int = 1000, temperature: float = 0.7) -> str:
        """Call the Gemini API with the given prompt"""
        try:
            response = self.gemini_model.generate_content(prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=max_tokens,
                    temperature=temperature
                )
            )
            return str(response.text)
        except Exception as e:
            print(f"Error calling Gemini API: {str(e)}")
            return None

def main():
    client = LLMClient()
    c_file_path = "example.c"
    
    with open(c_file_path, 'r') as f:
        original_code = f.read()
    
    model_responses = {}
    harness_summary = []
    
    for model in ["claude", "gpt", "gemini"]:
        print(f"\nGenerating {model.upper()} harness:")
        result = client.process_c_code(c_file_path, model=model)
        
        model_responses[model] = result['response']
        
        # Add to summary
        if result['harness_path']:
            harness_summary.append(f"{model.upper()}: {result['harness_path']}")
        else:
            harness_summary.append(f"{model.upper()}: Failed to generate harness")
    
    # Print harness generation summary
    print("\nHarness Generation Summary:")
    print("=" * 50)
    for summary in harness_summary:
        print(summary)
    print("=" * 50)
    
    # Save detailed report
    report_file = client.save_analysis_report(original_code, model_responses, c_file_path)
    print(f"\nDetailed analysis report saved to: {report_file}")
    
    # Print harness file locations
    if client.harness_files:
        print("\nGenerated Harness Files:")
        for orig_file, harnesses in client.harness_files.items():
            print(f"\nFor {orig_file}:")
            for model, path in harnesses.items():
                print(f"  {model}: {path}")

if __name__ == "__main__":
    main()