{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBMC-Compatible Harness Generation System - Part 3: Node Functions (First Half)\n",
    "\n",
    "This part implements the first set of node functions for our LangGraph workflow, including frontend processing, code embedding, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: Frontend - Initial processing of source code\n",
    "def frontend_node(state: HarnessGenerationState):\n",
    "    \"\"\"Processes the source code and prepares it for embedding.\"\"\"\n",
    "    \n",
    "    if not state.source_code:\n",
    "        # Extract source code from the latest message if available\n",
    "        for message in reversed(state[\"messages\"]):\n",
    "            if isinstance(message, HumanMessage) and \"```\" in message.content:\n",
    "                # Extract code between triple backticks\n",
    "                import re\n",
    "                match = re.search(r'```(?:\\w+)?\\n(.+?)\\n```', message.content, re.DOTALL)\n",
    "                if match:\n",
    "                    state.source_code = match.group(1)\n",
    "                    break\n",
    "    \n",
    "    # If no source code found, ask the user\n",
    "    if not state.source_code:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Please provide the source code you'd like to analyze for memory leaks.\")]\n",
    "        }\n",
    "    \n",
    "    # Proceed to the next step with the source code\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Received source code ({len(state.source_code)} characters). Proceeding with code embedding and analysis.\")],\n",
    "        \"source_code\": state.source_code\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 2: Code Embedding System\n",
    "def code_embedding_node(state: HarnessGenerationState):\n",
    "    \"\"\"Embeds the source code and stores it in the database.\"\"\"\n",
    "    \n",
    "    # Call the embedding tool\n",
    "    result = embed_code(state.source_code)\n",
    "    \n",
    "    # Store the embeddings\n",
    "    state.embeddings = result\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Source code embedded successfully. Found {len(result['functions'])} functions.\")],\n",
    "        \"embeddings\": result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 3: Analyzer (LLM Agent)\n",
    "def analyzer_node(state: HarnessGenerationState):\n",
    "    \"\"\"LLM-based analyzer that identifies potential memory leak vulnerabilities using ChromaDB.\"\"\"\n",
    "    \n",
    "    # Query ChromaDB for functions with potential memory leak indicators\n",
    "    # First, get all functions that have malloc but no free\n",
    "    potential_leaks = code_collection.get(\n",
    "        where={\"has_malloc\": True, \"has_free\": False}\n",
    "    )\n",
    "    \n",
    "    # Also get functions with both malloc and free for further analysis\n",
    "    functions_with_both = code_collection.get(\n",
    "        where={\"has_malloc\": True, \"has_free\": True}\n",
    "    )\n",
    "    \n",
    "    # Create a list of all function details to present to the LLM\n",
    "    all_functions = {}\n",
    "    \n",
    "    # Add potential leaks first\n",
    "    for i, func_id in enumerate(potential_leaks[\"ids\"]):\n",
    "        all_functions[func_id] = {\n",
    "            \"full_text\": potential_leaks[\"documents\"][i],\n",
    "            \"potential_leak\": True\n",
    "        }\n",
    "    \n",
    "    # Add other functions that use malloc\n",
    "    for i, func_id in enumerate(functions_with_both[\"ids\"]):\n",
    "        if func_id not in all_functions:\n",
    "            all_functions[func_id] = {\n",
    "                \"full_text\": functions_with_both[\"documents\"][i],\n",
    "                \"potential_leak\": False\n",
    "            }\n",
    "    \n",
    "    analyzer_prompt = f\"\"\"\n",
    "    You are a specialized code analyzer focused on identifying potential memory leaks in C code.\n",
    "    Analyze the following functions and identify those that might have memory leak vulnerabilities.\n",
    "    Look for patterns like:\n",
    "    1. Malloc without corresponding free\n",
    "    2. Conditional frees that might not execute\n",
    "    3. Error paths that don't properly clean up resources\n",
    "    4. Nested allocations with incomplete cleanup\n",
    "    \n",
    "    Here are the functions to analyze, with preliminary analysis from our system:\n",
    "    {json.dumps(all_functions, indent=2)}\n",
    "    \n",
    "    Some functions are already flagged with 'potential_leak: true' based on initial analysis.\n",
    "    Please verify these and check other functions for more complex memory leak patterns.\n",
    "    \n",
    "    For each suspicious function, use the query_pattern_db tool to find matching memory leak patterns.\n",
    "    \n",
    "    Output a list of function names that might have memory leaks, with a brief explanation for each.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM with the analyzer prompt\n",
    "    response = llm_with_tools.invoke(\n",
    "        [\n",
    "            SystemMessage(content=analyzer_prompt)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Process the analyzer response to extract vulnerable functions\n",
    "    # Check for tool calls to pattern_db in the response\n",
    "    vulnerable_functions = []\n",
    "    \n",
    "    # If tool calls were made, process their results\n",
    "    if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
    "        for tool_call in response.tool_calls:\n",
    "            if tool_call[\"name\"] == \"query_pattern_db\":\n",
    "                # Extract function name from the query if possible\n",
    "                query = tool_call[\"args\"]\n",
    "                for func_name in all_functions.keys():\n",
    "                    if func_name in str(query):\n",
    "                        if func_name not in vulnerable_functions:\n",
    "                            vulnerable_functions.append(func_name)\n",
    "    \n",
    "    # If no tool calls or vulnerable functions found, extract from content\n",
    "    if not vulnerable_functions:\n",
    "        for func_name in all_functions.keys():\n",
    "            if func_name.lower() in response.content.lower():\n",
    "                vulnerable_functions.append(func_name)\n",
    "    \n",
    "    # As a fallback, use our initial analysis\n",
    "    if not vulnerable_functions:\n",
    "        for func_name, func_info in all_functions.items():\n",
    "            if func_info.get(\"potential_leak\", False):\n",
    "                vulnerable_functions.append(func_name)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Analysis complete. Identified {len(vulnerable_functions)} potentially vulnerable functions: {', '.join(vulnerable_functions)}\")],\n",
    "        \"vulnerable_functions\": vulnerable_functions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 4: Junction - Routes each vulnerable function to the generator\n",
    "def junction_node(state: HarnessGenerationState):\n",
    "    \"\"\"Junction that creates processing tasks for each vulnerable function.\"\"\"\n",
    "    \n",
    "    # Simply pass through the state - in a real implementation, this might\n",
    "    # set up parallel processing or create a queue of functions to process\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Preparing to generate harnesses for each vulnerable function.\")]\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
